# Financial Detective Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider Selection
# =============================================================================
# Options: "openai" | "ollama" | "gemini"
LLM_PROVIDER=ollama

# =============================================================================
# OpenAI Configuration (required when LLM_PROVIDER=openai)
# =============================================================================
# OPENAI_API_KEY=sk-your-api-key-here

# =============================================================================
# Google Gemini Configuration (required when LLM_PROVIDER=gemini)
# =============================================================================
# GEMINI_API_KEY=your-gemini-api-key-here
# GEMINI_MODEL=gemini-2.0-flash
# Alternative models: gemini-1.5-flash, gemini-1.5-pro (check availability)

# =============================================================================
# Ollama Configuration (used when LLM_PROVIDER=ollama)
# =============================================================================
OLLAMA_MODEL=llama3:latest
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# Document Chunking Configuration
# =============================================================================
# Enable automatic chunking for large documents that exceed LLM context limits
CHUNK_ENABLED=true

# Target number of tokens per chunk (approximate)
# Recommended: 4000 for Ollama, 8000-32000 for OpenAI/Gemini
CHUNK_SIZE_TOKENS=4000

# Number of tokens to overlap between consecutive chunks
# Overlap preserves context across chunk boundaries
CHUNK_OVERLAP_TOKENS=200
